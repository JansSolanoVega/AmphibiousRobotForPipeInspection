{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0sYtMO55pvID"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "\n",
        "from torch.nn import functional as F\n",
        "from torchvision import transforms as T\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "import PIL\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVOqRmVYqHWQ",
        "outputId": "d06699ec-a1b4-4d9e-d3bf-76a63086b674"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**DATASET**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eaZSF_9FzHBQ"
      },
      "outputs": [],
      "source": [
        "TRAIN_IMAGES_PATH = 'Crack_Segmentation_Dataset/images'\n",
        "TRAIN_MASKS_PATH = 'Crack_Segmentation_Dataset/masks'\n",
        "TEST_PATH= 'Data/all/test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Checking folders\n",
        "images_files=os.listdir(TRAIN_IMAGES_PATH)\n",
        "masks_files=os.listdir(TRAIN_MASKS_PATH)\n",
        "for i in images_files:\n",
        "    if i not in masks_files:\n",
        "        os.remove(os.path.join(TRAIN_IMAGES_PATH, i))\n",
        "for i in masks_files:\n",
        "    if i not in images_files:\n",
        "        os.remove(os.path.join(TRAIN_MASKS_PATH, i))  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UuF7hcn7zspj"
      },
      "outputs": [],
      "source": [
        "# creating our own Dataset\n",
        "class CrackDataset(Dataset):\n",
        "    def __init__(self, data, masks=None, img_transforms=None, mask_transforms=None):\n",
        "        '''\n",
        "        data - train data path\n",
        "        masks - train masks path\n",
        "        '''\n",
        "        self.train_data = data\n",
        "        self.train_masks = masks\n",
        "        \n",
        "        self.img_transforms = img_transforms\n",
        "        self.mask_transforms = mask_transforms\n",
        "        \n",
        "        self.images = sorted(os.listdir(self.train_data)[:4000])\n",
        "        self.masks = sorted(os.listdir(self.train_masks)[:4000])\n",
        "        \n",
        "    def __len__(self):\n",
        "        if self.train_masks is not None:\n",
        "            assert len(self.images)==len(self.masks), 'not the same number of images and masks'\n",
        "        return len(self.images)\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        image_name = os.path.join(self.train_data, self.images[idx])\n",
        "        img = Image.open(image_name)\n",
        "        trans = T.ToTensor()\n",
        "        if self.img_transforms is not None:\n",
        "            img = self.img_transforms(img)\n",
        "        else:\n",
        "            img =trans(img)\n",
        "        \n",
        "        if self.train_masks is not None:\n",
        "            mask_name = os.path.join(self.train_masks, self.masks[idx])\n",
        "            mask = Image.open(mask_name)\n",
        "            if self.mask_transforms is not None:\n",
        "                mask = self.mask_transforms(mask)\n",
        "            else:\n",
        "                mask = trans(mask)\n",
        "            \n",
        "            #mask_max = mask.max().item()\n",
        "            #mask /= mask_max\n",
        "        else:\n",
        "            return img\n",
        "        \n",
        "        return img, mask    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PlfZIq5CGSVe"
      },
      "outputs": [],
      "source": [
        "transform_data = T.Compose([\n",
        "                T.Resize([224, 224]),\n",
        "                T.ToTensor(),\n",
        "                T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
        "\n",
        "transform_data_target = T.Compose([\n",
        "                T.Resize([224, 224]),\n",
        "                #T.Grayscale(1),\n",
        "                T.ToTensor(),\n",
        "                T.Lambda(lambda x: torch.where(x > 0.5, torch.tensor([1.0]), torch.tensor([0.0])))\n",
        "                ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCMKZuAfGVXv"
      },
      "outputs": [],
      "source": [
        "full_dataset = CrackDataset(TRAIN_IMAGES_PATH,\n",
        "                           TRAIN_MASKS_PATH,\n",
        "                           img_transforms=transform_data,\n",
        "                           mask_transforms=transform_data_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5nZjqYEWTvZ"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 8\n",
        "TRAIN_SIZE = int(len(full_dataset)*0.7)\n",
        "VAL_SIZE = int(len(full_dataset)*0.15)\n",
        "TEST_SIZE = len(full_dataset) - TRAIN_SIZE-VAL_SIZE\n",
        "print(TRAIN_SIZE, VAL_SIZE, TEST_SIZE)\n",
        "train_dataset, val_dataset, test_dataset = random_split(full_dataset, [TRAIN_SIZE, VAL_SIZE, TEST_SIZE])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Check image and mask\n",
        "id = 25\n",
        "fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
        "ax[0].imshow(train_dataset[id][0].permute(1, 2, 0));ax[0].set_title(\"Image\")\n",
        "ax[1].imshow(train_dataset[id][1][0],'binary');ax[1].set_title(\"Mask\")\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Dataloader**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lrhsky_kWc2t"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJ6P9ufpWgb9",
        "outputId": "076dbec3-ace8-44eb-e509-8c3343e07323"
      },
      "outputs": [],
      "source": [
        "imgs, masks = next(iter(train_loader))\n",
        "print(imgs.shape, masks.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        },
        "id": "POTLNRF8Wnu9",
        "outputId": "20934194-2ca7-4d0e-cf27-7755e94641e7"
      },
      "outputs": [],
      "source": [
        "imgs, masks = next(iter(train_loader))\n",
        "#print(masks)\n",
        "def plot_mini_batch(imgs, masks):\n",
        "    plt.figure(figsize=(20,10))\n",
        "    for i in range(BATCH_SIZE):\n",
        "        plt.subplot(4, 8, i+1)\n",
        "        img=imgs[i,...].permute(1,2,0).numpy()\n",
        "        mask = masks[i, ...][0].numpy()\n",
        "        #print(masks==1)\n",
        "        plt.imshow(img)\n",
        "        plt.imshow(mask, alpha=0.6)\n",
        "        \n",
        "        plt.axis('Off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_mini_batch(imgs, masks)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Model**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Creating model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import segmentation_models_pytorch as smp\n",
        "model = smp.Unet(encoder_name=\"resnet34\", encoder_weights=None, classes=2, activation='softmax')\n",
        "#model.classification_head = torch.nn.Conv2d(512, 2, kernel_size=1, stride=1)\n",
        "model.to(device)\n",
        "print(model)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def accuracy(model, loader):\n",
        "    correct = 0\n",
        "    intersection = 0\n",
        "    denom = 0\n",
        "    union = 0\n",
        "    total = 0\n",
        "    cost = 0.\n",
        "    model = model.to(device=device)\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device=device, dtype = torch.float32)\n",
        "            y = y.to(device=device, dtype = torch.long).squeeze(1)\n",
        "            scores = model(x)\n",
        "            cost += (F.cross_entropy(scores, y)).item()\n",
        "            # standard accuracy not optimal\n",
        "            preds = torch.argmax(scores, dim=1)\n",
        "            correct += (preds == y).sum()\n",
        "            total += torch.numel(preds)\n",
        "            #dice coefficient\n",
        "            intersection += (preds*y).sum()\n",
        "            denom += (preds + y).sum()\n",
        "            dice = 2*intersection/(denom + 1e-8)\n",
        "            #intersection over union\n",
        "            union += (preds + y - preds*y).sum()\n",
        "            iou = (intersection)/(union + 1e-8)\n",
        "            \n",
        "        return cost/len(loader), float(correct)/total, dice, iou    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# Writer will output to ./runs/ directory by default\n",
        "writer = SummaryWriter()\n",
        "val_losses = []\n",
        "train_losses = []\n",
        "\n",
        "train_accs = []\n",
        "val_accs = []\n",
        "\n",
        "train_iou = []\n",
        "val_iou = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(dataloader, model, loss_function, optimizer, epoch, store_every=9):\n",
        "    train_correct_num, train_total, train_cost_acum = 0, 0, 0.0\n",
        "    intersection, union = 0, 0\n",
        "    model.train()\n",
        "    for batch, (x,y) in enumerate(dataloader):\n",
        "        x = x.to(device=device, dtype=torch.float32)\n",
        "        y = y.to(device=device, dtype=torch.long).squeeze(1)\n",
        "        #print(x.shape)\n",
        "        scores = model(x)\n",
        "        cost = loss_function(input=scores, target=y)\n",
        "        #cost.requires_grad = True\n",
        "\n",
        "\n",
        "        #Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_predictions = torch.argmax(scores, dim=1)\n",
        "        train_correct_num += (train_predictions == y).sum()\n",
        "        train_total += torch.numel(train_predictions)#total numero de elementos de train_predictions, if size=[a,b,c ] returns a*b*c\n",
        "        train_cost_acum += cost\n",
        "        \n",
        "        #IOU\n",
        "        intersection += (train_predictions*y).sum()\n",
        "        union += (train_predictions + y - train_predictions*y).sum()\n",
        " \n",
        "        if batch % store_every == 1:#1 cuz division by zero\n",
        "            train_acc = float(train_correct_num)/train_total#el train total ya considera el batch\n",
        "            train_cost_every = float(train_cost_acum)/batch#Se divide entre el batch, xq por cada batch se aumenta el loss\n",
        "            iou_every = ((intersection)/(union + 1e-8)).item()\n",
        "            writer.add_scalar('training loss',\n",
        "                            train_cost_every,\n",
        "                            epoch * len(dataloader) + batch)#len(dataloader) returns total number of batchs in an epoch\n",
        "            writer.add_scalar('training accuracy',\n",
        "                            train_acc,\n",
        "                            epoch * len(dataloader) + batch)\n",
        "            writer.add_scalar('training IOU',\n",
        "                            iou_every,\n",
        "                            epoch * len(dataloader) + batch)\n",
        "            \n",
        "            print(\"loss: \", train_cost_every, \"Accuracy: \", train_acc, \"IOU: \", iou_every)\n",
        "            train_losses.append(train_cost_every)\n",
        "            train_accs.append(train_acc)\n",
        "            train_iou.append(iou_every)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def val(dataloader, model, loss_function,epoch):\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    val_loss, val_correct_num, val_total = 0.0, 0, 0\n",
        "    intersection, union = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in dataloader:\n",
        "            x = x.to(device=device, dtype=torch.float32)\n",
        "            y = y.to(device=device, dtype=torch.long).squeeze(1)\n",
        "            pred = model(x)\n",
        "            loss = loss_function(input=pred, target=y)\n",
        "            \n",
        "            val_loss += loss.item()\n",
        "            val_predictions = torch.argmax(pred, dim=1)\n",
        "            val_correct_num += ((val_predictions == y).sum()).item()\n",
        "            val_total += torch.numel(val_predictions)\n",
        "\n",
        "            #IOU\n",
        "            intersection += (val_predictions*y).sum()\n",
        "            union += (val_predictions + y - val_predictions*y).sum()\n",
        "\n",
        "    val_loss /= num_batches\n",
        "    val_correct_num = val_correct_num/val_total\n",
        "    IOU = ((intersection)/(union + 1e-8)).item()\n",
        "    writer.add_scalar('validation loss',\n",
        "                    val_loss,epoch)\n",
        "    writer.add_scalar('validation accuracy',\n",
        "                    val_correct_num,epoch)\n",
        "    writer.add_scalar('validation IOU',\n",
        "                    IOU,epoch)\n",
        "    print(f\"Validation Error: \\n Accuracy: {(100*val_correct_num):>0.1f}%, Avg loss: {val_loss:>8f}, IOU: {IOU:>0.3f} \\n\")\n",
        "    val_losses.append(val_loss)\n",
        "    val_accs.append(val_correct_num)\n",
        "    val_iou.append(IOU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()#Hace el softmax y la funcion costo al mismo tiempo\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "epochs = 20\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
        "    train(train_loader, model, loss_fn, optimizer, epoch)\n",
        "    val(val_loader, model, loss_fn, epoch)\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot([los for los in train_losses], label='train_loss')\n",
        "plt.plot(val_losses,label='val_loss')\n",
        "plt.legend()\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(train_accs, label='train_acc')\n",
        "plt.plot([ac.data.cpu() for ac in val_accs], label='val_acc')\n",
        "plt.legend()\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"UNET_resnet34_10k_Images_0_01_Dict.pth\")\n",
        "torch.save(model, \"UNET_resnet34_10k_Images_0_01_DictComplete.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "imgs_val, masks_val = next(iter(test_loader))\n",
        "imgs_val = imgs_val.to(device, dtype=torch.float32)\n",
        "model = model.to(device)\n",
        "with torch.no_grad():\n",
        "    scores = model(imgs_val)\n",
        "    print(scores.shape)\n",
        "    preds = torch.argmax(scores, dim=1).float()\n",
        "    print(preds==1)\n",
        "imgs_val = imgs_val.cpu()\n",
        "preds = preds.cpu()\n",
        "#print(preds.shape)\n",
        "plot_mini_batch(imgs_val, preds.unsqueeze(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import segmentation_models_pytorch as smp\n",
        "import torch\n",
        "# Cargar el modelo entrenado\n",
        "model_read = smp.Unet(encoder_name=\"resnet34\", encoder_weights=None, classes=2, activation='softmax')\n",
        "model_read.load_state_dict(torch.load('unet_Without_TF_resnet34_4kImages_97_Dict.pth'))\n",
        "\n",
        "# Establecer el modelo en modo de evaluaci√≥n\n",
        "model_read.eval()\n",
        "\n",
        "\n",
        "imgs_val, masks_val = next(iter(val_loader))\n",
        "imgs_val = imgs_val.to(device, dtype=torch.float32)\n",
        "model_read = model_read.to(device)\n",
        "with torch.no_grad():\n",
        "    scores = model_read(imgs_val)\n",
        "    #print(scores.shape)\n",
        "    preds = torch.argmax(scores, dim=1).float()\n",
        "    #print(preds==1)\n",
        "imgs_val = imgs_val.cpu()\n",
        "preds = preds.cpu()\n",
        "#print(preds.shape)\n",
        "plot_mini_batch(imgs_val, preds.unsqueeze(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "5109d816b82be14675a6b11f8e0f0d2e80f029176ed3710d54e125caa8520dfd"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
